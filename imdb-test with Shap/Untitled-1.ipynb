{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 3000\n",
    "maxlen=80\n",
    "batch_size=100\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 194,\n",
       " 1153,\n",
       " 194,\n",
       " 2,\n",
       " 78,\n",
       " 228,\n",
       " 5,\n",
       " 6,\n",
       " 1463,\n",
       " 2,\n",
       " 2,\n",
       " 134,\n",
       " 26,\n",
       " 4,\n",
       " 715,\n",
       " 8,\n",
       " 118,\n",
       " 1634,\n",
       " 14,\n",
       " 394,\n",
       " 20,\n",
       " 13,\n",
       " 119,\n",
       " 954,\n",
       " 189,\n",
       " 102,\n",
       " 5,\n",
       " 207,\n",
       " 110,\n",
       " 2,\n",
       " 21,\n",
       " 14,\n",
       " 69,\n",
       " 188,\n",
       " 8,\n",
       " 30,\n",
       " 23,\n",
       " 7,\n",
       " 4,\n",
       " 249,\n",
       " 126,\n",
       " 93,\n",
       " 4,\n",
       " 114,\n",
       " 9,\n",
       " 2300,\n",
       " 1523,\n",
       " 5,\n",
       " 647,\n",
       " 4,\n",
       " 116,\n",
       " 9,\n",
       " 35,\n",
       " 2,\n",
       " 4,\n",
       " 229,\n",
       " 9,\n",
       " 340,\n",
       " 1322,\n",
       " 4,\n",
       " 118,\n",
       " 9,\n",
       " 4,\n",
       " 130,\n",
       " 2,\n",
       " 19,\n",
       " 4,\n",
       " 1002,\n",
       " 5,\n",
       " 89,\n",
       " 29,\n",
       " 952,\n",
       " 46,\n",
       " 37,\n",
       " 4,\n",
       " 455,\n",
       " 9,\n",
       " 45,\n",
       " 43,\n",
       " 38,\n",
       " 1543,\n",
       " 1905,\n",
       " 398,\n",
       " 4,\n",
       " 1649,\n",
       " 26,\n",
       " 2,\n",
       " 5,\n",
       " 163,\n",
       " 11,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1153,\n",
       " 9,\n",
       " 194,\n",
       " 775,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 349,\n",
       " 2637,\n",
       " 148,\n",
       " 605,\n",
       " 2,\n",
       " 2,\n",
       " 15,\n",
       " 123,\n",
       " 125,\n",
       " 68,\n",
       " 2,\n",
       " 2,\n",
       " 15,\n",
       " 349,\n",
       " 165,\n",
       " 2,\n",
       " 98,\n",
       " 5,\n",
       " 4,\n",
       " 228,\n",
       " 9,\n",
       " 43,\n",
       " 2,\n",
       " 1157,\n",
       " 15,\n",
       " 299,\n",
       " 120,\n",
       " 5,\n",
       " 120,\n",
       " 174,\n",
       " 11,\n",
       " 220,\n",
       " 175,\n",
       " 136,\n",
       " 50,\n",
       " 9,\n",
       " 2,\n",
       " 228,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 656,\n",
       " 245,\n",
       " 2350,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 131,\n",
       " 152,\n",
       " 491,\n",
       " 18,\n",
       " 2,\n",
       " 32,\n",
       " 2,\n",
       " 1212,\n",
       " 14,\n",
       " 9,\n",
       " 6,\n",
       " 371,\n",
       " 78,\n",
       " 22,\n",
       " 625,\n",
       " 64,\n",
       " 1382,\n",
       " 9,\n",
       " 8,\n",
       " 168,\n",
       " 145,\n",
       " 23,\n",
       " 4,\n",
       " 1690,\n",
       " 15,\n",
       " 16,\n",
       " 4,\n",
       " 1355,\n",
       " 5,\n",
       " 28,\n",
       " 6,\n",
       " 52,\n",
       " 154,\n",
       " 462,\n",
       " 33,\n",
       " 89,\n",
       " 78,\n",
       " 285,\n",
       " 16,\n",
       " 145,\n",
       " 95]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 56s 221ms/step - loss: 0.4519 - accuracy: 0.7798 - val_loss: 0.3669 - val_accuracy: 0.8380\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.3452 - accuracy: 0.8509 - val_loss: 0.3833 - val_accuracy: 0.8288\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 0.3134 - accuracy: 0.8643 - val_loss: 0.3752 - val_accuracy: 0.8356\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.2832 - accuracy: 0.8786 - val_loss: 0.3705 - val_accuracy: 0.8370\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.2538 - accuracy: 0.8920 - val_loss: 0.4007 - val_accuracy: 0.8335\n",
      "250/250 [==============================] - 12s 49ms/step - loss: 0.4007 - accuracy: 0.8335\n",
      "[0.4006572961807251, 0.8335199952125549]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "model.fit(x_train, y_train, batch_size=batch_size,epochs=5,validation_data=(x_test, y_test))\n",
    "score=model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlime\u001b[39;00m \u001b[39mimport\u001b[39;00m lime_text\n\u001b[1;32m      2\u001b[0m explainer \u001b[39m=\u001b[39m lime_text\u001b[39m.\u001b[39mLimeTextExplainer(verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m explanation \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain_instance(x_test[\u001b[39m10\u001b[39;49m], classifier_fn\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict, labels\u001b[39m=\u001b[39;49my_test[\u001b[39m10\u001b[39;49m])\n\u001b[1;32m      4\u001b[0m explanation\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/picture_class_proj2/lib/python3.10/site-packages/lime/lime_text.py:409\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplain_instance\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    369\u001b[0m                      text_instance,\n\u001b[1;32m    370\u001b[0m                      classifier_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m                      distance_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    376\u001b[0m                      model_regressor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    377\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generates explanations for a prediction.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \n\u001b[1;32m    379\u001b[0m \u001b[39m    First, we generate neighborhood data by randomly hiding features from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m        explanations.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     indexed_string \u001b[39m=\u001b[39m (IndexedCharacters(\n\u001b[1;32m    407\u001b[0m         text_instance, bow\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbow, mask_string\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_string)\n\u001b[1;32m    408\u001b[0m                       \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchar_level \u001b[39melse\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m                       IndexedString(text_instance, bow\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbow,\n\u001b[1;32m    410\u001b[0m                                     split_expression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_expression,\n\u001b[1;32m    411\u001b[0m                                     mask_string\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask_string))\n\u001b[1;32m    412\u001b[0m     domain_mapper \u001b[39m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[1;32m    413\u001b[0m     data, yss, distances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__data_labels_distances(\n\u001b[1;32m    414\u001b[0m         indexed_string, classifier_fn, num_samples,\n\u001b[1;32m    415\u001b[0m         distance_metric\u001b[39m=\u001b[39mdistance_metric)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/picture_class_proj2/lib/python3.10/site-packages/lime/lime_text.py:114\u001b[0m, in \u001b[0;36mIndexedString.__init__\u001b[0;34m(self, raw_string, split_expression, bow, mask_string)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[39m# with the split_expression as a non-capturing group (?:), we don't need to filter out\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[39m# the separator character from the split results.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     splitter \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)|$\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m split_expression)\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_list \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m splitter\u001b[39m.\u001b[39;49msplit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw) \u001b[39mif\u001b[39;00m s]\n\u001b[1;32m    115\u001b[0m     non_word \u001b[39m=\u001b[39m splitter\u001b[39m.\u001b[39mmatch\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mas_list)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "from lime import lime_text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# Convert your data into text strings\n",
    "\n",
    "texts = tokenizer.sequences_to_texts(x_test)\n",
    "\n",
    "explainer = lime_text.LimeTextExplainer(verbose=True)\n",
    "explanation = explainer.explain_instance(x_test[10], classifier_fn=model.predict, labels=y_test[10])\n",
    "explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_folder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
